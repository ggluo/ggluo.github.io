<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>A hands-on tutorial for spreco | Guanxiong Jason Luo</title> <meta name="author" content="Guanxiong Jason Luo"> <meta name="description" content="spreco, generative pretraining, image priors"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%86&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ggluo.github.io/projects/0_back/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Guanxiong Luo</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">A hands-on tutorial for spreco</h1> <p class="post-meta">July 24, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/spreco"> <i class="fas fa-hashtag fa-sm"></i> spreco</a>   <a href="/blog/tag/tutorials"> <i class="fas fa-hashtag fa-sm"></i> tutorials</a>     ·   <a href="/blog/category/work"> <i class="fas fa-tag fa-sm"></i> work</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> ## Overview This post will give a brief introduction to the usage of [spreco](https://github.com/mrirecon/spreco). Spreco is a tool for MR researchers to train generative priors for image reconstruction, developed with TensorFlow. It is recommended to use it on a Linux-based system. The same to most workflows in deep learning, we can use it following steps below. 1. The preparation of data 2. Training of generative priors 3. Export and inference 4. Feedback ## Preparation of data Before embarking on any ML projects, the first thing come up is where to get data for training. Except collecting your own data, specifically in the field of medical imaging, there so many datasets are made publicly available for researchers. I found a list on this github [repository](https://github.com/sfikas/medical-imaging-datasets). Then many questions follow up. How large is the dataset? Is it necessary to do preprocessing before using it? Do I have enough computation resources to work on it? From my own experiences, the preprocessing step could be time-consuming, and it is always beneficial to parallelize your tasks. If the tasks are cpu-based, the python library [multiprocessing](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing) is a good option. If the tasks are gpu-based, one possible trick is to have a small snippet for one task and then use shell script to parallelize multiple snippets for tasks over the available gpus. In the end, make sure to store processed files in an organized way.By doing this, it would be easier to define a dataloader for training. When your data is heavy and it takes long to load, here is one data loading pipeline, [Tensorpack DataFlow](https://github.com/tensorpack/dataflow), optimized for speed. To prepare data for spreco after finishing the preprocessing step, you need to create a list of training files specifying where the files are. Shell commands `ls` and `find` are so efficient to do so. ```text ./dataset/abide_2/train/abide_1000000.npz ./dataset/abide_2/train/abide_1000001.npz ./dataset/abide_2/train/abide_1000002.npz ./dataset/abide_2/train/abide_1000003.npz ``` ## Training of generative priors I assume nowadays most labs are equipped with workstations that have multiple gpus, keeping track of hyperparameters needs a good deal of patience and monitoring the training is important. Spreco provides a workable solution for these things with one yaml config file. ### Configuration file ```yml # parameters for the model model: 'PIXELCNN' batch_size: 6 input_shape: [256, 256, 2] nr_resnet: 3 nr_filters: 128 nr_logistic_mix: 10 data_chns: 'CPLX' dropout_rate: 0.5 itg_interval: 255.0 rlt: 1 layer_norm: False conditional: False # learning rate schedule lr_warm_up_steps: 1000 lr_start: 0.0001 lr_min: 0.0001 lr_max: 0.0001 lr_max_decay_steps: 2000 max_keep: 100 max_epochs: 500 save_interval: 50 # take a snapshot every 50 epochs saved_name: pixelcnn log_folder: ./logs/ # where to save the snapshots of the model num_prepare: 10 print_loss: True train_list: train_list test_list: test_list nr_gpu: 4 gpu_id: '0,1,2,3' ``` ### Script for training After the configuration file is done, you need to write a script to start training that includes the read of configuration file, the initialization of the dataloader, and the start of the trainer. The below is an example. Once the training is started, you can use TensorBoard to monitor the losses for training by specifying where the log folder is. ```python from spreco.common import utils from spreco.trainer import trainer from spreco.dataflow.base import RNGDataFlow from spreco.dataflow.common import BatchData from spreco.dataflow.parallel_map import MultiThreadMapData import os import numpy as np import argparse class cfl_pipe(RNGDataFlow): def __init__(self, files, shuffle): self._size = len(files) self.files = files self.shuffle = shuffle def __len__(self): return len(self.files) def __iter__(self): idxs = np.arange(self._size) if self.shuffle: self.rng.shuffle(idxs) for idx in idxs: fname = self.files[idx] yield fname def main(config_path): config = utils.load_config(config_path) train_files = utils.read_filelist(config['train_list']) test_files = utils.read_filelist(config['test_list']) def load_file(x): """ x ---&gt; file path imgs ---&gt; normalized images with shape (batch_size, x, y, 2) """ path, ext = os.path.splitext(x) imgs = np.squeeze(utils.readcfl(path)) imgs = imgs / np.max(np.abs(imgs), axis=(1,2), keepdims=True) imgs = utils.cplx2float(imgs) return imgs def map_f(x): d = aug_load_file(x) return {"inputs": d} nr_elm = config['batch_size']*config['nr_gpu'] d1 = cfl_pipe(train_files, True) d1 = MultiThreadMapData(d1, num_thread=config['num_thread'], map_func=map_f, buffer_size=nr_elm*10, strict=True) train_pipe = BatchData(d1, nr_elm, use_list=False) d2 = cfl_pipe(test_files, True) d2 = MultiThreadMapData(d2, num_thread=config['num_thread'], map_func=map_f, buffer_size=nr_elm*10, strict=True) test_pipe = BatchData(d2, nr_elm, use_list=False) go = trainer(train_pipe, test_pipe, config) utils.log_to(os.path.join(go.log_path, 'train_files'), train_files) utils.log_to(os.path.join(go.log_path, 'test_files'), test_files) utils.log_to(os.path.join(go.log_path, 'train_info'), [utils.get_timestamp() + ", the training is starting"]) go.train() utils.log_to(os.path.join(go.log_path, 'train_info'), [utils.get_timestamp() + ", the training is ending"]) utils.color_print('TRAINING FINISHED at ' + utils.get_timestamp()) if __name__ == "__main__": parser = argparse.ArgumentParser(description='') parser.add_argument('--config', metavar='path', default='config file for training', help='') args = parser.parse_args() main(args.config) ``` ## Export and inference For every model in spreco, you can use the `exporter` module to export the trained models. It exports the neural network with default inputs and outputs. You can load the exported graph and inference it with [BART](https://github.com/mrirecon/bart) toolbox. It is possible to customize the inputs and outputs. The below is an example for handling 2D MR images. Click here for [3D volumes](https://github.com/ggluo/image-priors/blob/release/scripts/recon/create_graph.py). ```python from spreco.exporter import exporter from spreco.common import utils import tensorflow.compat.v1 as tf tf.disable_eager_execution() import numpy as np e = exporter(log = "./PixelCNN/cplx_large", meta = "pixelcnn", default_out=False, path="./PixelCNN/exported", name="cplx_large", gpu_id='0') x = tf.placeholder(tf.float32, shape=[1, 256, 256, 2], name="input_0") logits = e.model.eval(x) loss = e.model.loss_func(x, logits) / np.log(2.0) / np.prod([1, 256, 256, 2]) e.export([x], [loss], attach_gradients=True) ``` We prepare a complete [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ggluo/image-priors/blob/release/misc/demo_image_priors_colab.ipynb) to demonstrate how to use the trained generative priors when using BART for image reconstruction. Once you have gone through the whole workflow, you can start to collect feedback and iterate models. If there is any question or feedback for us, feel free to leave them below. </div> </article><div id="giscus_thread" style="max-width: 850px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Guanxiong Jason Luo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>