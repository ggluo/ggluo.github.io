<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Deploy generative image priors for image reconstruction using BART | Guanxiong Luo</title> <meta name="author" content="Guanxiong Luo"> <meta name="description" content="MR image reconstruction, model deployment, TensorFlow C API, TensorFlow computation graph"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%86&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ggluo.github.io/projects/bart-tf-mri-reconstruction"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Guanxiong Luo</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/index.html">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deploy generative image priors for image reconstruction using BART</h1> <p class="post-description">MR image reconstruction, model deployment, TensorFlow C API, TensorFlow computation graph</p> </header> <article> <div style="float: right; margin-left: 1rem; margin-bottom: 0rem"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="/assets/img/projects/bart_tf/bart_tf-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="/assets/img/projects/bart_tf/bart_tf-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/bart_tf/bart_tf-1400.webp"></source> <img src="/assets/img/projects/bart_tf/bart_tf.png" class="img-fluid rounded z-depth-1" width="400" height="auto" title="overview" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption_post"> Figure 1. Overview of the proposed method. </div> </div> <p><strong><code class="language-plaintext highlighter-rouge">Abstract</code></strong> As the image priors are almost always trained in an offline setting using Python, this work aims to deploy the trained model with an MR image reconstruction toolbox, <strong><a href="https://github.com/mrirecon/bart" rel="external nofollow noopener" target="_blank">BART</a></strong>, which is a versatile tool for image reconstruction. As shown in Figure 1, there are two steps to realize this: (a) export the constructed computation graph with TensorFlow; (b) use the graph as regularization in BART.</p> <p>The deployment of models trained with spreco into BART requires minimum environmental prerequisites, providing a practical and user-friendly solution for medical image reconstruction tasks.</p> <div style="float: right; margin-left: 1rem; margin-bottom: 0rem; margin-top: 1rem"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="/assets/img/projects/bart_tf/spreco-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="/assets/img/projects/bart_tf/spreco-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/bart_tf/spreco-1400.webp"></source> <img src="/assets/img/projects/bart_tf/spreco.png" class="img-fluid rounded z-depth-1" width="400" height="auto" title="spreco" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption_post"> Figure 2. The structure of spreco. </div> </div> <p><strong><code class="language-plaintext highlighter-rouge">Method</code></strong> We developed a Python library for training generative models, <strong><a href="https://github.com/mrirecon/spreco" rel="external nofollow noopener" target="_blank">spreco</a></strong>, based on TensorFlow, which has the following features:</p> <ol> <li>Distributed training</li> <li>Interruptible training</li> <li>Efficient dataloader for medical images</li> <li>Customizable with a configuration file</li> </ol> <p>And we trained a log-likelihood prior, \(\log p({x};\mathtt{NET}(\hat{\Theta}, {x}))\)<a href="https://arxiv.org/abs/1701.05517" rel="external nofollow noopener" target="_blank">\(^1\)</a><a href="https://arxiv.org/abs/2011.13456" rel="external nofollow noopener" target="_blank">\(^{,\ 2}\)</a>, which is used to impose learned prior knowledge of images in the SENSE model. The reconstruction is commonly formulated as the following minimization problem \begin{equation} \hat{x}=\underset{x}{\arg\min}\ |\mathcal{A}{x}-{y}|_2^2 + \lambda \log p({x};\mathtt{NET}(\hat{\Theta}, {x})),\nonumber \label{eq:1} \end{equation} where the first term ensures data consistency between the acquired <a href="https://en.wikipedia.org/wiki/K-space_(magnetic_resonance_imaging)" rel="external nofollow noopener" target="_blank">k-space</a> data \({y}\) and the desired image \({x}\), \(\mathcal{A}\) is the forward operator. This problem is solved with <a href="https://www.ceremade.dauphine.fr/~carlier/FISTA" rel="external nofollow noopener" target="_blank">FISTA</a> algorithm that has been implemented in BART. To use the learned log-likelihood prior with BART, we have implemented a <a href="https://github.com/mrirecon/bart/commit/8b8d4ed2a727bcbc19a11e9ddd64d46f7e5e21d9" rel="external nofollow noopener" target="_blank">wrapper</a> using <a href="[$$^1$$](https://www.tensorflow.org/install/lang_c)">TensorFlow C API</a> for the initialization, restoration and inference of the exported trained model. Click here <a href="https://colab.research.google.com/github/mrirecon/bart-workshop/blob/master/ismrm2021/bart_tensorflow/bart_tf.ipynb" rel="external nofollow noopener" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> and give a quick tryout!</p> <p>Figure 3 displays the evolution of image during the process of reconstruction.</p> <div style="margin-bottom: 0rem"> <div style="margin-bottom: -0.5rem"> <figure> <video src="/assets/img/projects/bart_tf/r_evo.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" muted=""></video> </figure> </div> <div class="caption_post" style="margin-bottom: 1rem"> Figure 3. The left sub-figure shows the evolution of the probability density function (PDF) (dashed curves) and the empirically learned PDF (solid curves) at five selected pixels over iterations. The middle sub-figure shows the evolution of magnitude image. The right sub-figure shows the convergence of metrics. </div> </div> <p><strong><code class="language-plaintext highlighter-rouge">Conclusion</code></strong> We showcased the seamless integration of a TensorFlow trained model into the existing MRI reconstruction workflows of the BART toolbox. This integration allows us to leverage the image reconstruction capabilities offered by BART while harnessing the advantages of rapid prototyping of advanced deep learning models using TensorFlow.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MRM</abbr><br> <span class="badge"><span style="color:rgb(85, 151, 113)">Highlighted</span></span> </div> <div id="Blumenthal_Magn.Reson.Med._2023" class="col-sm-8"> <div class="title">Deep, deep learning with BART</div> <div class="author"> Moritz Blumenthal, <em>Guanxiong Luo</em>, Martin Schilling, H. Christian M. Holme, and Martin Uecker</div> <div class="periodical"> <em>Magn. Reson. Med.</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Blumenthal_Magn.Reson.Med._2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/mrirecon/deep-deep-learning-with-bart" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Purpose To develop a deep-learning-based image reconstruction framework for reproducible research in MRI. Methods The BART toolbox offers a rich set of implementations of calibration and reconstruction algorithms for parallel imaging and compressed sensing. In this work, BART was extended by a nonlinear operator framework that provides automatic differentiation to allow computation of gradients. Existing MRI-specific operators of BART, such as the nonuniform fast Fourier transform, are directly integrated into this framework and are complemented by common building blocks used in neural networks. To evaluate the use of the framework for advanced deep-learning-based reconstruction, two state-of-the-art unrolled reconstruction networks, namely the Variational Network and MoDL, were implemented. Results State-of-the-art deep image-reconstruction networks can be constructed and trained using BART’s gradient-based optimization algorithms. The BART implementation achieves a similar performance in terms of training time and reconstruction quality compared to the original implementations based on TensorFlow. Conclusion By integrating nonlinear operators and neural networks into BART, we provide a general framework for deep-learning-based reconstruction in MRI.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ISMRM</abbr><br> <span class="badge"><span style="color:rgb(85, 151, 113)">Poster</span></span> </div> <div id="Luo__2021_a" class="col-sm-8"> <div class="title">Using data-driven image priors for image reconstruction with BART</div> <div class="author"> <em>Guanxiong Luo</em>, Moritz Blumenthal, and Martin Uecker</div> <div class="periodical"> Oct 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/bart_tf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://colab.research.google.com/github/mrirecon/bart-workshop/blob/master/ismrm2021/bart_tensorflow/bart_tf.ipynb" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://index.mirasmart.com/ISMRM2021/PDFfiles/1756.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Guanxiong Luo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: November 05, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>