<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Self-diffusion Driven Blind Imaging | Guanxiong Luo</title> <meta name="author" content="Guanxiong Luo"> <meta name="description" content="CVPR 2026, Computational imaging, Blind image deblur, Self-diffusion, Inverse problem, Optical aberrations"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%86&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ggluo.github.io/projects/DeblurSDI"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Guanxiong Luo</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/index.html">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Self-diffusion Driven Blind Imaging</h1> <p class="post-description">CVPR 2026, Computational imaging, Blind image deblur, Self-diffusion, Inverse problem, Optical aberrations</p> </header> <article> <p><strong><code class="language-plaintext highlighter-rouge">TLDR</code></strong> We propose DeblurSDI, a training-free and hyperparameter-insensitive framework that leverages self-diffusion to jointly recover sharp images and Point Spread Functions (PSFs). It introduces explicit modeling of optical aberrations via Zernike polynomials and demonstrates state-of-the-art performance on both optical aberration correction and motion deblurring tasks. The full paper is available <a href="https://arxiv.org/abs/2510.27439v2" rel="external nofollow noopener" target="_blank">here</a> and the code is available <a href="https://github.com/ggluo/DeblurSDI" rel="external nofollow noopener" target="_blank">here</a>.</p> <h2 id="introduction">Introduction</h2> <p>Optical imaging systems are inherently imperfect due to diffraction limits, lens manufacturing tolerances, assembly misalignment, and other physical constraints. Additionally, unavoidable camera shake and object motion introduce non-ideal degradations during acquisition. These aberrations and motion-induced variations are typically unknown, difficult to measure, and costly to model or calibrate in practice.</p> <p>Blind inverse problems offer a promising direction by jointly estimating both the latent image and the unknown degradation kernel. However, existing approaches often suffer from convergence instability, limited prior expressiveness, and sensitivity to hyperparameters. Motivated by recent advances in self-diffusion, we propose <strong>DeblurSDI</strong>, a zero-shot, self-supervised blind imaging framework that requires no pre-training.</p> <h2 id="key-contributions">Key Contributions</h2> <p>This paper makes three key contributions:</p> <ol> <li> <p><strong>DeblurSDI Framework</strong>: We propose a training-free and self-supervised framework for blind image recovery that integrates self-diffusion to jointly estimate both the sharp image and the PSF without external priors.</p> </li> <li> <p><strong>Physical Degradation Modeling</strong>: We construct evaluation datasets that include optical-aberration PSFs modeled via Zernike polynomials and motion-blur kernels, enabling comprehensive assessment under challenging conditions.</p> </li> <li> <p><strong>State-of-the-Art Performance</strong>: We demonstrate that DeblurSDI achieves consistently superior performance and robustness compared to state-of-the-art blind deblurring methods, particularly in stability and PSF estimation.</p> </li> </ol> <h2 id="method">Method</h2> <h3 id="31-modeling-optical-aberrations">3.1 Modeling Optical Aberrations</h3> <p>To simulate realistic optical degradations, we adopt the standard wavefront–pupil–PSF formulation widely used in computational optics. Optical aberrations are represented through a weighted sum of <strong>Zernike polynomials</strong>, which form an orthonormal basis on the unit disk and accurately model low- and high-order aberration modes such as defocus, astigmatism, coma, spherical aberration, trefoil, and quadrafoil.</p> <p>Let \((\rho,\theta)\) denote polar coordinates on the normalized pupil domain. The Zernike polynomial of radial order \(n\) and azimuthal order \(m\) is defined as:</p> \[Z_n^m(\rho,\theta) = \begin{cases} R_n^{|m|}(\rho)\cos(m\theta), &amp; m \geq 0, \\ R_n^{|m|}(\rho)\sin(|m|\theta), &amp; m &lt; 0, \end{cases}\] <p>where the radial term \(R_n^m(\rho)\) is given by:</p> \[R_n^m(\rho) = \sum_{k=0}^{\frac{n-m}{2}} (-1)^k \frac{(n-k)!}{k! \left(\tfrac{n+m}{2}-k\right)! \left(\tfrac{n-m}{2}-k\right)!} \rho^{\,n-2k}.\] <p>A wavefront corrupted by multiple aberrations can therefore be written as:</p> \[W(\rho,\theta) = \sum_{(n,m)\in\mathcal{A}} a_{n,m} Z_n^m(\rho,\theta),\] <p>where each coefficient \(a_{n,m}\) controls the severity of the corresponding aberration mode. In our simulations, we include all Zernike modes up to order \(n=4\), which are sufficient to reproduce a wide range of realistic aberration patterns observed in lens-based imaging systems.</p> <h3 id="32-blind-imaging-via-self-diffusion">3.2 Blind Imaging via Self-Diffusion</h3> <p>We extend the self-diffusion framework to address blind optical correction. The forward model for blind image deblurring is given by:</p> \[\mathbf{y} = \mathbf{x}_{\text{true}} \circledast \mathbf{k} + n,\] <p>where \(\circledast\) denotes convolution, the sharp image \(\mathbf{x}_{\text{true}} \in \mathbb{R}^{H \times W \times C}\) and the PSF \(\mathbf{k} \in \mathbb{R}^{K \times K \times 1}\) are both unknown.</p> <p>We employ two dedicated, randomly initialized networks: an <strong>image denoiser \(D_\theta\)</strong> to restore \(\mathbf{x}_{\text{true}}\), and a <strong>PSF generator \(G_\phi\)</strong> to produce \(\mathbf{k}\). Our method simulates a reverse diffusion process over \(T\) discrete time steps, starting with random noise for both the image estimate, \(\mathbf{x}_T\), and the PSF estimate, \(\mathbf{z}_T\).</p> <p>At each time step \(t \in \{T,T-1,\ldots,1\}\), the current estimates are perturbed with scheduled noise:</p> \[\hat{\mathbf{x}}_t = \mathbf{x}_t + \sigma_t \cdot \epsilon_x, \quad \text{and} \quad \hat{\mathbf{z}}_t = \mathbf{z}_t + \sigma'_t \cdot \epsilon_z,\] <p>where \(\epsilon_x \sim \mathcal{N}(0,\mathbf{I})\) and \(\epsilon_z \sim \mathcal{N}(0,\mathbf{I})\). The noise schedule is \(\sigma_t = \sqrt{1-\bar{\alpha}_t}\), where \(\bar{\alpha}_t = \prod_{i=0}^t (1-\beta_i)\) and \(\beta_t = \beta_{\text{end}} + \frac{t}{T-1}(\beta_{\text{start}} - \beta_{\text{end}})\), and \(\sigma'_t = \mu\sigma_t\), with \(\mu\) as an adjustable hyperparameter.</p> <p>The both networks are jointly optimized within an inner loop by minimizing the following objective:</p> \[\mathcal{L}_t(\theta,\phi) = \|(D_\theta(\hat{\mathbf{x}}_t) \circledast G_\phi(\hat{\mathbf{z}}_t)) - \mathbf{y}\|_2^2 + \lambda_k R(G_\phi(\hat{\mathbf{z}}_t))\] <p>where \(R(\cdot)\) is an L1-norm regularization to enforce sparsity on the generated PSF, which is known to be sparse in practice.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="https://arxiv.org/html/2510.27439v2/x1-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="https://arxiv.org/html/2510.27439v2/x1-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://arxiv.org/html/2510.27439v2/x1-1400.webp"></source> <img src="https://arxiv.org/html/2510.27439v2/x1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="PSFs for Individual and Combined Aberrations" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> PSFs for individual and combined aberrations (defocus, coma, astigmatism, spherical, coma+spherical, defocus+coma). Upper row: wavefronts. Lower row: PSFs. </div> <h2 id="results">Results</h2> <h3 id="41-visualization-of-iterative-process">4.1 Visualization of Iterative Process</h3> <p>As shown in the evolution figures, the scheduled injection of noise effectively “shakes” the optimization out of local minima, allowing it to explore a broader solution space before converging on a high-fidelity reconstruction.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="/assets/img/projects/DeblurSDI/evo-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="/assets/img/projects/DeblurSDI/evo-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/DeblurSDI/evo-1400.webp"></source> <img src="/assets/img/projects/DeblurSDI/evo.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Evolution of Image and Kernel Estimates" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Evolution of image and kernel estimates during DeblurSDI's reverse diffusion process. The "up-down-up" curve in the PSNR graph highlights how noise scheduling prevents premature convergence to local optima. </div> <h3 id="42-optical-aberration-correction">4.2 Optical Aberration Correction</h3> <p>We evaluated DeblurSDI on six simulated optical aberrations (defocus, coma, astigmatism, spherical, coma+spherical, defocus+coma) against state-of-the-art methods. The quantitative results demonstrate DeblurSDI’s superior performance:</p> <p><strong>Table 1: Optical Aberration Correction Performance (PSNR/SSIM)</strong></p> <table> <thead> <tr> <th>Method</th> <th>Levin Dataset</th> <th>Kohler Dataset</th> <th>FFHQ Dataset</th> </tr> </thead> <tbody> <tr> <td>Phase-Only</td> <td>15.52/0.3722</td> <td>27.37/0.7889</td> <td>26.31/0.7703</td> </tr> <tr> <td>FFT-ReLU Deblur</td> <td>19.57/0.5655</td> <td>29.89/0.8358</td> <td>23.21/0.6942</td> </tr> <tr> <td>SelfDeblur</td> <td>18.13/0.4706</td> <td>20.76/0.5409</td> <td>19.65/0.5591</td> </tr> <tr> <td>FastDiffusionEM</td> <td>18.68/0.5085</td> <td>19.83/0.5242</td> <td>17.90/0.4508</td> </tr> <tr> <td><strong>DeblurSDI (Ours)</strong></td> <td><strong>28.36/0.8598</strong></td> <td><strong>32.07/0.9061</strong></td> <td><strong>33.00/0.9343</strong></td> </tr> </tbody> </table> <p><br></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="https://arxiv.org/html/2510.27439v2/x7-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="https://arxiv.org/html/2510.27439v2/x7-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://arxiv.org/html/2510.27439v2/x7-1400.webp"></source> <img src="https://arxiv.org/html/2510.27439v2/x7.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Optical Aberration Correction Results" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Reconstruction results of DeblurSDI on optical aberration situations. Our method consistently recovers accurate PSFs and sharp images across different aberration types. </div> <h3 id="43-motion-deblurring-performance">4.3 Motion Deblurring Performance</h3> <p>We conducted extensive experiments on four benchmark datasets (Levin, Cho, Kohler, and FFHQ) to evaluate motion deblurring performance. DeblurSDI demonstrates remarkable robustness across different kernel sizes:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="https://arxiv.org/html/2510.27439v2/x6-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="https://arxiv.org/html/2510.27439v2/x6-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://arxiv.org/html/2510.27439v2/x6-1400.webp"></source> <img src="https://arxiv.org/html/2510.27439v2/x6.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Robustness to Kernel Size Variations" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Performance and stability comparison across different kernel sizes. DeblurSDI (blue) consistently achieves the highest scores and demonstrates remarkable stability, with its performance remaining largely unaffected by changes in kernel size. </div> <p><strong>Table 2: Motion Deblurring Performance (PSNR/SSIM)</strong></p> <table> <thead> <tr> <th>Method</th> <th>Levin Dataset</th> <th>Cho Dataset</th> <th>Kohler Dataset</th> <th>FFHQ Dataset</th> </tr> </thead> <tbody> <tr> <td>Phase-Only</td> <td>20.68/0.6061</td> <td>19.89/0.6746</td> <td>28.23/0.8092</td> <td>25.80/0.7904</td> </tr> <tr> <td>FFT-ReLU Deblur</td> <td>15.56/0.3845</td> <td>18.73/0.6546</td> <td>25.33/0.7140</td> <td>21.71/0.6579</td> </tr> <tr> <td>SelfDeblur</td> <td>25.06/0.7301</td> <td>20.37/0.6844</td> <td>21.97/0.5995</td> <td>19.82/0.5563</td> </tr> <tr> <td>FastDiffusionEM</td> <td>16.55/0.4005</td> <td>15.39/0.4687</td> <td>18.85/0.4813</td> <td>15.59/0.3592</td> </tr> <tr> <td><strong>DeblurSDI (Ours)</strong></td> <td><strong>31.85/0.7911</strong></td> <td><strong>28.73/0.8859</strong></td> <td><strong>29.17/0.7653</strong></td> <td><strong>33.90/0.9064</strong></td> </tr> </tbody> </table> <h3 id="44-qualitative-results">4.4 Qualitative Results</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="https://arxiv.org/html/2510.27439v2/x10-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="https://arxiv.org/html/2510.27439v2/x10-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://arxiv.org/html/2510.27439v2/x10-1400.webp"></source> <img src="https://arxiv.org/html/2510.27439v2/x10.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="FFHQ Dataset Results" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Deblurring results on the FFHQ dataset. DeblurSDI maintains structural integrity and recovers sharp details even under heavy motion blur, while accurately estimating the blur kernel. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 1000px)" srcset="https://arxiv.org/html/2510.27439v2/x9-1000.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1200px)" srcset="https://arxiv.org/html/2510.27439v2/x9-1200.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://arxiv.org/html/2510.27439v2/x9-1400.webp"></source> <img src="https://arxiv.org/html/2510.27439v2/x9.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Cho Dataset Results" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Deblurring results on the Cho dataset. Our method consistently outperforms other approaches in recovering fine details and accurate kernel structures. </div> <h2 id="conclusion">Conclusion</h2> <p>Through solving blind inverse problems to recover images under optical aberrations and motion blur, we investigate a novel and robust solution for image deblurring. The plausible performance and robustness of our proposed method are brought about by the noise schedule, which is a key component of the self-diffusion framework. We astutely observed this characteristic and extended it to solving extremely unstable joint optimization inverse problems, greatly addressing the problem of unstable solutions or collapse into trivial solutions.</p> <p>While our method requires longer runtime compared to others due to simultaneous constraints on both the image and kernel with neural networks and hierarchical noise scheduling, this investment is worthwhile because we significantly improve the realism of recovered images across the continuous spectrum, especially high-frequency details.</p> <h2 id="citation">Citation</h2> <p>If you find our work useful, please cite our CVPR 2026 paper:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yang2025selfdiffusion</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Self-diffusion Driven Blind Imaging}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Yang, Yanlong and Luo, Guanxiong}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2026}</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="resources">Resources</h3> <ul> <li> <strong>Paper</strong>: <a href="https://arxiv.org/abs/2510.27439v2" rel="external nofollow noopener" target="_blank">arXiv:2510.27439v2</a> </li> <li> <strong>Code</strong>: <a href="https://github.com/ggluo/DeblurSDI" rel="external nofollow noopener" target="_blank">GitHub Repository</a> </li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Guanxiong Luo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: February 23, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-L1ZL85W5Y4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-L1ZL85W5Y4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>